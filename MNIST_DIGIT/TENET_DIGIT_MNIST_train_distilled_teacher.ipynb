{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TENET_DIGIT_MNIST_train_distilled_teacher.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "h89DmUFLFq0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4364db6-cec9-41f5-8668-82478d73398d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5jyCZJTFtk6"
      },
      "source": [
        "#!ls \"/content/gdrive/MyDrive/\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zrcxr5YZKhF",
        "outputId": "b192b26f-c1b4-4aab-a455-1a7c8d5462a5"
      },
      "source": [
        "!git clone https://github.com/knamdar/data.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'data'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 16 (delta 2), reused 16 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RCmKuVNy9Dz",
        "outputId": "c0bb9bee-5cfe-4f3a-d0ac-66c7f1b6ecdc"
      },
      "source": [
        "!pip install foolbox"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting foolbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ff/1ba817ad9aa7c2ca28fb809d64939bee7311e3e62fdd87c4011232c4640e/foolbox-3.3.1-py3-none-any.whl (1.7MB)\n",
            "\r\u001b[K     |▏                               | 10kB 21.9MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 29.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 35.1MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 30.0MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 31.8MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61kB 33.4MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71kB 29.3MB/s eta 0:00:01\r\u001b[K     |█▋                              | 81kB 30.5MB/s eta 0:00:01\r\u001b[K     |█▊                              | 92kB 32.1MB/s eta 0:00:01\r\u001b[K     |██                              | 102kB 31.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 112kB 31.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 122kB 31.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 133kB 31.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 143kB 31.7MB/s eta 0:00:01\r\u001b[K     |███                             | 153kB 31.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 163kB 31.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 174kB 31.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 184kB 31.7MB/s eta 0:00:01\r\u001b[K     |███▊                            | 194kB 31.7MB/s eta 0:00:01\r\u001b[K     |████                            | 204kB 31.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 215kB 31.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 225kB 31.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 235kB 31.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 245kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 256kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 266kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 276kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 286kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 296kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 307kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 317kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 327kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 337kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 348kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 358kB 31.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 368kB 31.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 378kB 31.7MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 389kB 31.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 399kB 31.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 409kB 31.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 419kB 31.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 430kB 31.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 440kB 31.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 450kB 31.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 460kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 471kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 481kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 491kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 501kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 512kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 522kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 532kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 542kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 552kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 563kB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 573kB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 583kB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 593kB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 604kB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 614kB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 624kB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 634kB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 645kB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 655kB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 665kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 675kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 686kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 696kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 706kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 716kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 727kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 737kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 747kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 757kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 768kB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 778kB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 788kB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 798kB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 808kB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 819kB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 829kB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 839kB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 849kB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 860kB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 870kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 880kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 890kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 901kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 911kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 921kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 931kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 942kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 952kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 962kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 972kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 983kB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 993kB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.0MB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.0MB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.0MB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.0MB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.0MB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.1MB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.1MB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.1MB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.1MB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1MB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.1MB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.1MB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.1MB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.1MB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.1MB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.2MB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.2MB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.2MB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.2MB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2MB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.2MB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.2MB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.2MB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.2MB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.2MB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.3MB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.3MB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.3MB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.3MB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3MB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.3MB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.3MB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.3MB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.3MB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4MB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.4MB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.4MB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.4MB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.4MB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.4MB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.4MB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.4MB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.4MB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.4MB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5MB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5MB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.5MB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.5MB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.5MB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5MB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5MB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.5MB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.5MB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.5MB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.6MB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.6MB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.6MB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.6MB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.6MB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.6MB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.6MB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.6MB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.6MB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.6MB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.7MB 31.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7MB 31.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.19.5)\n",
            "Collecting eagerpy==0.29.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/07/54994565da4fc5a4840d3a434fb9bf3835b4a4e68c931ccfcc327d568f95/eagerpy-0.29.0-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.4.1)\n",
            "Collecting GitPython>=3.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/91/b38c4fabb6e5092ab23492ded4f318ab7299b19263272b703478038c0fbc/GitPython-3.1.18-py3-none-any.whl (170kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 45.6MB/s \n",
            "\u001b[?25hCollecting requests>=2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.7/dist-packages (from foolbox) (3.7.4.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from foolbox) (57.0.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2021.5.30)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2.10)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: eagerpy, smmap, gitdb, GitPython, requests, foolbox\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed GitPython-3.1.18 eagerpy-0.29.0 foolbox-3.3.1 gitdb-4.0.7 requests-2.25.1 smmap-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90DONPc-ZCLs"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import foolbox as fb\n",
        "from foolbox import PyTorchModel, accuracy, samples\n",
        "from foolbox.attacks import LinfPGD,LinfBasicIterativeAttack,LinfFastGradientAttack,L2CarliniWagnerAttack,LinfDeepFoolAttack,L2DeepFoolAttack,L2BasicIterativeAttack,L2ProjectedGradientDescentAttack\n",
        "\n",
        "class Model_Drop(nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Model_Drop, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3,padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3,padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3,padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3,padding=1)\n",
        "        self.fc1 = nn.Linear(7*7*64, 200)\n",
        "        self.fc2 = nn.Linear(200, 200)\n",
        "        self.fc3 = nn.Linear(200, 10)\n",
        "        self.drop_layer = nn.Dropout(p=0.50)\n",
        "\n",
        "    def last_hidden_layer_output(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
        "        x = x.view(-1, 7*7*64)\n",
        "        x = self.drop_layer((F.relu(self.fc1(x))))\n",
        "        x = self.drop_layer((F.relu(self.fc2(x))))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.last_hidden_layer_output(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "mnist_train = datasets.MNIST(\"data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_test = datasets.MNIST(\"data\", train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(mnist_train, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=128, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "torch.manual_seed(2)\n",
        "torch.cuda.manual_seed(2)\n",
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "def enable_dropout(model):\n",
        "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
        "    for m in model.modules():\n",
        "        if m.__class__.__name__.startswith('Dropout'):\n",
        "            m.train()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "T = 20\n",
        "\n",
        "def epoch(loader, model, opt=None):\n",
        "\n",
        "    if opt:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_loss, total_err = 0., 0.\n",
        "\n",
        "    for X, y in loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        \n",
        "        outputs = model(X)\n",
        "\n",
        "        log_prob_s = F.log_softmax(outputs / T, dim=1)\n",
        "\n",
        "        loss = F.nll_loss(log_prob_s,y)\n",
        "        #loss = criterion(log_prob_s, y)\n",
        "\n",
        "        if opt:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        total_err += (outputs.max(dim=1)[1] != y).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-H24ZCH2J-M",
        "outputId": "df440510-a272-493b-feb0-ca7f447107bb"
      },
      "source": [
        "model_cnn = Model_Drop()\n",
        "model_cnn.to(device)\n",
        "\n",
        "opt = optim.Adam(model_cnn.parameters(), lr=0.001)\n",
        "#opt = optim.SGD(model_cnn.parameters(), lr=0.1, momentum=0.5)\n",
        "\n",
        "for te in range(30):\n",
        "\n",
        "    #if te == 4:\n",
        "      #for param_group in opt.param_groups:\n",
        "        #param_group[\"lr\"] = 1e-3\n",
        "\n",
        "    train_err, train_loss = epoch(train_loader, model_cnn, opt)\n",
        "    test_err, test_loss = epoch(test_loader, model_cnn) \n",
        "\n",
        "    print(*(\"{:.6f}\".format(i) for i in (train_err, test_err)), sep=\"\\t\")\n",
        "    #print(train_err)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.169867\t0.025500\n",
            "0.041700\t0.017400\n",
            "0.030150\t0.014500\n",
            "0.025017\t0.014800\n",
            "0.021050\t0.010500\n",
            "0.018000\t0.010600\n",
            "0.015517\t0.010000\n",
            "0.014067\t0.009000\n",
            "0.012917\t0.011400\n",
            "0.012117\t0.008200\n",
            "0.010733\t0.007900\n",
            "0.011017\t0.006900\n",
            "0.009050\t0.007900\n",
            "0.009750\t0.007800\n",
            "0.008467\t0.006800\n",
            "0.007250\t0.007800\n",
            "0.007150\t0.007900\n",
            "0.007100\t0.007400\n",
            "0.006383\t0.006100\n",
            "0.006533\t0.007100\n",
            "0.005983\t0.006100\n",
            "0.005000\t0.005300\n",
            "0.005183\t0.006600\n",
            "0.005133\t0.005600\n",
            "0.004300\t0.006300\n",
            "0.004933\t0.006900\n",
            "0.004550\t0.006300\n",
            "0.003983\t0.007400\n",
            "0.003817\t0.008200\n",
            "0.004617\t0.006100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXoQsJUH2MZ2",
        "outputId": "8ed284ad-93dd-429a-aedb-c379c171c05d"
      },
      "source": [
        "model_cnn.eval()\n",
        "torch.save(model_cnn.state_dict(), \"TENET_DIGIT_MNIST_model_cnn_teacher_T_20.pt\")\n",
        "\n",
        "model_cnn.load_state_dict(torch.load(\"TENET_DIGIT_MNIST_model_cnn_teacher_T_20.pt\"))\n",
        "model_cnn.eval()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model_Drop(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=3136, out_features=200, bias=True)\n",
              "  (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (fc3): Linear(in_features=200, out_features=10, bias=True)\n",
              "  (drop_layer): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBHgXmWJF1dO"
      },
      "source": [
        "torch.save(model_cnn.state_dict(), \"/content/gdrive/MyDrive/TENET_DIGIT_MNIST_model_cnn_teacher_T_20.pt\")"
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}