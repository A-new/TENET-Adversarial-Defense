{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TENET_DIGIT_MNIST_try_on_corrects_student_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmOzglIRDfVs",
        "outputId": "2655193d-7e9c-428f-bbdd-22581d605001"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3FaqGjiDjEi"
      },
      "source": [
        "#!ls \"/content/gdrive/MyDrive/\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZxyRd3mkmYJ"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import numpy as np\n",
        "import warnings\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from datetime import datetime\n",
        "import torchvision.models as models"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liOF1Yzbk3yg"
      },
      "source": [
        "class Model_Drop(nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Model_Drop, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3,padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3,padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3,padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3,padding=1)\n",
        "        self.fc1 = nn.Linear(7*7*64, 200)\n",
        "        self.fc2 = nn.Linear(200, 200)\n",
        "        self.fc3 = nn.Linear(200, 10)\n",
        "        self.drop_layer = nn.Dropout(p=0.50)\n",
        "\n",
        "    def last_hidden_layer_output(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
        "        x = x.view(-1, 7*7*64)\n",
        "        x = self.drop_layer((F.relu(self.fc1(x))))\n",
        "        x = self.drop_layer((F.relu(self.fc2(x))))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.last_hidden_layer_output(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_prs4zHwI75y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb73e184-580b-45df-95a7-8154d2afe67b"
      },
      "source": [
        "print(\"Please chose reversal method you would like to test 0, 1, 2 :\\n Epistemic Uncertainty Based (0)\\n  Scibilic Uncertainty Based (1)\\n Scibilic Uncertainty Based (For Pred Class only) (2)\\n\")\n",
        "\n",
        "input_a = int(input())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please chose reversal method you would like to test 0, 1, 2 :\n",
            " Epistemic Uncertainty Based (0)\n",
            "  Scibilic Uncertainty Based (1)\n",
            " Scibilic Uncertainty Based (For Pred Class only) (2)\n",
            "\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlqqEQr2BOC2",
        "outputId": "39d4f1ff-8c25-467a-c7d0-84029b1ec0cf"
      },
      "source": [
        "!git clone https://github.com/knamdar/data.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'data'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 16 (delta 2), reused 16 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkaC3xUqk6Jh"
      },
      "source": [
        "def unc_defense(image,model,epsilon, num_iter, alpha):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model((image+delta).clamp(0,1))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "\n",
        "        variance = torch.var(dropout_predictions, dim=0)\n",
        "\n",
        "        var = variance.mean(1,True)\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta).clamp(0, 1))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model((image + delta).clamp(0, 1))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIkn759FIuCs"
      },
      "source": [
        "def unc_defense_epistemic(image,model,epsilon, num_iter, alpha):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "    torch.cuda.manual_seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model((image+delta).clamp(0,1))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "        mean = torch.mean(dropout_predictions, dim=0)\n",
        "        pred_mean = mean\n",
        "\n",
        "        aleatoric = torch.zeros([item_count,10,10])\n",
        "        epistemic = torch.zeros([item_count,10,10])\n",
        "\n",
        "        for ti in range(50):\n",
        "\n",
        "            pred_t = dropout_predictions[ti]\n",
        "\n",
        "            aleatoric += torch.diag_embed(pred_t, offset=0, dim1=-2, dim2=-1) - pred_t[:, :, None] @ pred_t[:, None, :]\n",
        "            epistemic += (pred_t - pred_mean)[:, :, None] @ (pred_t - pred_mean)[:, None, :]\n",
        "\n",
        "\n",
        "        aleatoric = aleatoric / 50\n",
        "        epistemic = epistemic / 50\n",
        "\n",
        "        ep = epistemic.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "        al = aleatoric.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "\n",
        "        sc = ep / al\n",
        "  \n",
        "\n",
        "        var = ep\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta).clamp(0, 1))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model((image + delta).clamp(0, 1))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "            #delta.data -= alpha * delta_unc / (norms(delta_unc) + 1e-30)\n",
        "            #delta.data = torch.min(torch.max(delta.detach(), -image), 1 - image)  # clip X+delta to [0,1]\n",
        "            #delta.data *= epsilon / norms(delta.detach()).clamp(min=epsilon)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrFweMkJ-UNy"
      },
      "source": [
        "def unc_defense_scibilic(image,model,epsilon, num_iter, alpha):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "    torch.cuda.manual_seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model((image+delta).clamp(0,1))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "        mean = torch.mean(dropout_predictions, dim=0)\n",
        "        pred_mean = mean\n",
        "\n",
        "        aleatoric = torch.zeros([item_count,10,10])\n",
        "        epistemic = torch.zeros([item_count,10,10])\n",
        "\n",
        "        for ti in range(50):\n",
        "\n",
        "            pred_t = dropout_predictions[ti]\n",
        "\n",
        "            aleatoric += torch.diag_embed(pred_t, offset=0, dim1=-2, dim2=-1) - pred_t[:, :, None] @ pred_t[:, None, :]\n",
        "            epistemic += (pred_t - pred_mean)[:, :, None] @ (pred_t - pred_mean)[:, None, :]\n",
        "\n",
        "\n",
        "        aleatoric = aleatoric / 50\n",
        "        epistemic = epistemic / 50\n",
        "\n",
        "        ep = epistemic.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "        al = aleatoric.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "\n",
        "        sc = ep / al\n",
        "        #sc = al / ep\n",
        "\n",
        "        var = sc\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta).clamp(0, 1))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model((image + delta).clamp(0, 1))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "            #delta.data -= alpha * delta_unc / (norms(delta_unc) + 1e-30)\n",
        "            #delta.data = torch.min(torch.max(delta.detach(), -image), 1 - image)  # clip X+delta to [0,1]\n",
        "            #delta.data *= epsilon / norms(delta.detach()).clamp(min=epsilon)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyaAPiJWP_4d"
      },
      "source": [
        "def unc_defense_scibilic_pred(image,model,epsilon, num_iter, alpha,preds):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "    torch.cuda.manual_seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model((image+delta).clamp(0,1))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "        mean = torch.mean(dropout_predictions, dim=0)\n",
        "        pred_mean = mean\n",
        "\n",
        "        aleatoric = torch.zeros([item_count,10,10])\n",
        "        epistemic = torch.zeros([item_count,10,10])\n",
        "\n",
        "        for ti in range(50):\n",
        "\n",
        "            pred_t = dropout_predictions[ti]\n",
        "\n",
        "\n",
        "            #print(\"item_count\",item_count)\n",
        "            #print(\"pred_t shape\", pred_t.shape)\n",
        "            #print(\"aleatoric shape\", aleatoric.shape)\n",
        "            #print(\"squezed shape\", squezed_pred_t.shape)\n",
        "            #print(\"outer product shape\", (pred_t[:, :, None] @ pred_t[:, None, :]).shape)\n",
        "            #print(\"diag size is \", torch.diag_embed(pred_t, offset=0, dim1=-2, dim2=-1).shape)\n",
        "\n",
        "            aleatoric += torch.diag_embed(pred_t, offset=0, dim1=-2, dim2=-1) - pred_t[:, :, None] @ pred_t[:, None, :]\n",
        "            epistemic += (pred_t - pred_mean)[:, :, None] @ (pred_t - pred_mean)[:, None, :]\n",
        "\n",
        "\n",
        "        aleatoric = aleatoric / 50\n",
        "        epistemic = epistemic / 50\n",
        "\n",
        "        preds = preds.to(device)\n",
        "        epistemic = epistemic.to(device)\n",
        "        aleatoric = aleatoric.to(device)\n",
        "\n",
        "\n",
        "        ep = epistemic.diagonal(dim1=-2, dim2=-1).gather(1, preds.unsqueeze(1))\n",
        "        al = aleatoric.diagonal(dim1=-2, dim2=-1).gather(1, preds.unsqueeze(1))\n",
        "\n",
        "        #ep = epistemic.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "        #al = aleatoric.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "\n",
        "        sc = ep / al\n",
        "        #sc = al / ep\n",
        "\n",
        "        var = sc\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta).clamp(0, 1))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            #print(torch.count_nonzero(delta_unc)/delta_unc.shape[0])\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "            #delta.data -= alpha * delta_unc / (norms(delta_unc) + 1e-30)\n",
        "            #delta.data = torch.min(torch.max(delta.detach(), -image), 1 - image)  # clip X+delta to [0,1]\n",
        "            #delta.data *= epsilon / norms(delta.detach()).clamp(min=epsilon)\n",
        "\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model((image + delta).clamp(0, 1))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            #print(torch.count_nonzero(delta_unc)/delta_unc.shape[0])\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "            #delta.data -= alpha * delta_unc / (norms(delta_unc) + 1e-30)\n",
        "            #delta.data = torch.min(torch.max(delta.detach(), -image), 1 - image)  # clip X+delta to [0,1]\n",
        "            #delta.data *= epsilon / norms(delta.detach()).clamp(min=epsilon)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9nHaPjxk-Su"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "torch.manual_seed(2)\n",
        "np.random.seed(2)\n",
        "torch.cuda.manual_seed(2)\n",
        "\n",
        "batch_size = 64\n",
        "eps = 0.1\n",
        "alpha = 0.2 * eps\n",
        "num_iter = 10\n",
        "eps_l2 = 1.35\n",
        "\n",
        "eps_little = 0.02\n",
        "alpha_reverse = 0.2 * eps_little\n",
        "num_iter_reverse = 10\n",
        "\n",
        "count_successful_reverse = 0\n",
        "count_unsuccessful_reverse = 0\n",
        "\n",
        "count_successfull_attack = 0\n",
        "count_unsuccessfull_attack = 0\n",
        "\n",
        "\n",
        "test_data = datasets.MNIST(root='data', train=False, download=False, transform=transforms.ToTensor())\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKYU8kLvlBbs",
        "outputId": "4fcc0182-bf5d-43d2-e389-d30b82c6e7c9"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_cnn = Model_Drop()\n",
        "model_cnn.load_state_dict(torch.load(\"/content/gdrive/MyDrive/TENET_DIGIT_MNIST_model_cnn_student_T_20.pt\",map_location=device))\n",
        "model_cnn.eval()\n",
        "model_cnn.to(device)\n",
        "\n",
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "def enable_dropout(model):\n",
        "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
        "    for m in model.modules():\n",
        "        if m.__class__.__name__.startswith('Dropout'):\n",
        "            m.train()\n",
        "\n",
        "corrects = []\n",
        "corrects_tuple_list = []\n",
        "\n",
        "reformatted_GMT_timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "print(reformatted_GMT_timestamp)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-29 10:25:32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26UWUseylEcr"
      },
      "source": [
        "for i, (image, label) in enumerate(test_loader):\n",
        "\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    pert = image\n",
        "\n",
        "    model_cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn(pert)\n",
        "        o = softmax(o)\n",
        "    pred_pert = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "\n",
        "    pred_pert = pred_pert.view_as(label)\n",
        "\n",
        "\n",
        "    inds_correct_after_attack = np.where(pred_pert.cpu() == label.cpu())[0]\n",
        "    inds_wrong_after_attack = np.where(pred_pert.cpu() != label.cpu())[0]\n",
        "\n",
        "\n",
        "    #if inds_wrong_after_attack.shape[0] == 0:\n",
        "      #continue\n",
        "\n",
        "\n",
        "    image = image[inds_correct_after_attack]\n",
        "    label = label[inds_correct_after_attack]\n",
        "    pert = pert[inds_correct_after_attack]\n",
        "    pred_pert = pred_pert[inds_correct_after_attack]\n",
        "\n",
        "    if input_a == 0:\n",
        "      reversed_pert = unc_defense_epistemic(pert, model_cnn, eps_little, num_iter_reverse, alpha_reverse)\n",
        "    elif input_a == 1:\n",
        "      reversed_pert = unc_defense_scibilic(pert, model_cnn, eps_little, num_iter_reverse, alpha_reverse)\n",
        "    elif input_a == 2:\n",
        "      reversed_pert = unc_defense_scibilic_pred(pert, model_cnn, eps_little, num_iter_reverse, alpha_reverse,pred_pert)\n",
        "\n",
        "    model_cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn(reversed_pert)\n",
        "        o = softmax(o)\n",
        "    pred_reverse = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    pred_reverse = pred_reverse.view_as(label)\n",
        "\n",
        "    inds_correct_after_reverse = np.where(pred_reverse.cpu() == label.cpu())[0]\n",
        "    inds_wrong_after_reverse = np.where(pred_reverse.cpu() != label.cpu())[0]\n",
        "\n",
        "    inds_correct_after_reverse = inds_correct_after_reverse.tolist()\n",
        "    inds_wrong_after_reverse = inds_wrong_after_reverse.tolist()\n",
        "\n",
        "    count_successful_reverse += len(inds_correct_after_reverse)\n",
        "    count_unsuccessful_reverse += len(inds_wrong_after_reverse)\n",
        "\n",
        "    # if i == 0:\n",
        "    #     break"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V62DntrMlHw3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "552d4dff-434a-4c1f-ca97-f10a1643b90e"
      },
      "source": [
        "print(\"Number of successful reverse operation is : \", count_successful_reverse)\n",
        "print(\"Number of unsuccessful reverse operation is : \", count_unsuccessful_reverse)\n",
        "\n",
        "reformatted_GMT_timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "print(reformatted_GMT_timestamp)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of successful reverse operation is :  9884\n",
            "Number of unsuccessful reverse operation is :  57\n",
            "2021-06-29 10:31:48\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}