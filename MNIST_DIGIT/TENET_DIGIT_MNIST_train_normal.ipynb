{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TENET_DIGIT_MNIST_train_normal.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "h89DmUFLFq0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2da567f-805d-485d-beae-a5aec8ded94d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5jyCZJTFtk6"
      },
      "source": [
        "#!ls \"/content/gdrive/MyDrive/\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zrcxr5YZKhF",
        "outputId": "084f73f0-de28-4f6b-ea8d-9fe563096073"
      },
      "source": [
        "!git clone https://github.com/knamdar/data.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'data'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 16 (delta 2), reused 16 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RCmKuVNy9Dz",
        "outputId": "fc37cb83-e672-483b-9ec0-6eee4724cb9e"
      },
      "source": [
        "!pip install foolbox"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting foolbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ff/1ba817ad9aa7c2ca28fb809d64939bee7311e3e62fdd87c4011232c4640e/foolbox-3.3.1-py3-none-any.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.4.1)\n",
            "Collecting GitPython>=3.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/91/b38c4fabb6e5092ab23492ded4f318ab7299b19263272b703478038c0fbc/GitPython-3.1.18-py3-none-any.whl (170kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 54.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from foolbox) (57.0.0)\n",
            "Collecting eagerpy==0.29.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/07/54994565da4fc5a4840d3a434fb9bf3835b4a4e68c931ccfcc327d568f95/eagerpy-0.29.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.19.5)\n",
            "Collecting requests>=2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 11.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.7/dist-packages (from foolbox) (3.7.4.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 13.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (3.0.4)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: smmap, gitdb, GitPython, eagerpy, requests, foolbox\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed GitPython-3.1.18 eagerpy-0.29.0 foolbox-3.3.1 gitdb-4.0.7 requests-2.25.1 smmap-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90DONPc-ZCLs"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import foolbox as fb\n",
        "from foolbox import PyTorchModel, accuracy, samples\n",
        "from foolbox.attacks import LinfPGD,LinfBasicIterativeAttack,LinfFastGradientAttack,L2CarliniWagnerAttack,LinfDeepFoolAttack,L2DeepFoolAttack,L2BasicIterativeAttack,L2ProjectedGradientDescentAttack\n",
        "\n",
        "class Model_Drop(nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Model_Drop, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3,padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3,padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3,padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3,padding=1)\n",
        "        self.fc1 = nn.Linear(7*7*64, 200)\n",
        "        self.fc2 = nn.Linear(200, 200)\n",
        "        self.fc3 = nn.Linear(200, 10)\n",
        "        self.drop_layer = nn.Dropout(p=0.50)\n",
        "\n",
        "    def last_hidden_layer_output(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
        "        x = x.view(-1, 7*7*64)\n",
        "        x = self.drop_layer((F.relu(self.fc1(x))))\n",
        "        x = self.drop_layer((F.relu(self.fc2(x))))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.last_hidden_layer_output(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "mnist_train = datasets.MNIST(\"data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_test = datasets.MNIST(\"data\", train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(mnist_train, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=128, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "torch.manual_seed(2)\n",
        "torch.cuda.manual_seed(2)\n",
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "def enable_dropout(model):\n",
        "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
        "    for m in model.modules():\n",
        "        if m.__class__.__name__.startswith('Dropout'):\n",
        "            m.train()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "T = 1\n",
        "\n",
        "def epoch(loader, model, opt=None):\n",
        "\n",
        "    if opt:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_loss, total_err = 0., 0.\n",
        "\n",
        "    for X, y in loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        \n",
        "        outputs = model(X)\n",
        "\n",
        "        log_prob_s = F.log_softmax(outputs / T, dim=1)\n",
        "\n",
        "        loss = F.nll_loss(log_prob_s,y)\n",
        "        #loss = criterion(log_prob_s, y)\n",
        "\n",
        "        if opt:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        total_err += (outputs.max(dim=1)[1] != y).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-H24ZCH2J-M",
        "outputId": "6c5860f5-c8e3-444f-f971-728764e09e6c"
      },
      "source": [
        "model_cnn = Model_Drop()\n",
        "model_cnn.to(device)\n",
        "\n",
        "opt = optim.Adam(model_cnn.parameters(), lr=0.001)\n",
        "#opt = optim.SGD(model_cnn.parameters(), lr=0.1, momentum=0.5)\n",
        "\n",
        "for te in range(10):\n",
        "\n",
        "\n",
        "    train_err, train_loss = epoch(train_loader, model_cnn, opt)\n",
        "    test_err, test_loss = epoch(test_loader, model_cnn) \n",
        "\n",
        "    print(*(\"{:.6f}\".format(i) for i in (train_err, test_err)), sep=\"\\t\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.124100\t0.019200\n",
            "0.030100\t0.011800\n",
            "0.023117\t0.010900\n",
            "0.016617\t0.010000\n",
            "0.014400\t0.008400\n",
            "0.012167\t0.008100\n",
            "0.010983\t0.006200\n",
            "0.009483\t0.007600\n",
            "0.009150\t0.006400\n",
            "0.008100\t0.008900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXoQsJUH2MZ2",
        "outputId": "4d589c87-b8f0-40ca-c484-62499bb2d239"
      },
      "source": [
        "model_cnn.eval()\n",
        "torch.save(model_cnn.state_dict(), \"TENET_DIGIT_MNIST_model_cnn_normal.pt\")\n",
        "\n",
        "model_cnn.load_state_dict(torch.load(\"TENET_DIGIT_MNIST_model_cnn_normal.pt\"))\n",
        "model_cnn.eval()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model_Drop(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=3136, out_features=200, bias=True)\n",
              "  (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (fc3): Linear(in_features=200, out_features=10, bias=True)\n",
              "  (drop_layer): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBHgXmWJF1dO"
      },
      "source": [
        "torch.save(model_cnn.state_dict(), \"/content/gdrive/MyDrive/TENET_DIGIT_MNIST_model_cnn_normal.pt\")"
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}