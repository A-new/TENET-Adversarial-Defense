{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TENET_DIGIT_MNIST_try_on_BPDA_Attack.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "awZ-vXCYt801",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9339b45-d117-4e04-9d14-9b7c9a596072"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVpBTrQEuCDy"
      },
      "source": [
        "#!ls \"/content/gdrive/MyDrive/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq672y9uNbTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c83a309-df7a-4083-92f9-e166b5148b93"
      },
      "source": [
        "!pip install foolbox"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: foolbox in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.7/dist-packages (from foolbox) (3.10.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from foolbox) (57.4.0)\n",
            "Requirement already satisfied: eagerpy==0.29.0 in /usr/local/lib/python3.7/dist-packages (from foolbox) (0.29.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.7/dist-packages (from foolbox) (2.26.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.4.1)\n",
            "Requirement already satisfied: GitPython>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from foolbox) (3.1.24)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=3.0.7->foolbox) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox) (5.0.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahil687EbJ8K",
        "outputId": "dd19d93a-236d-433c-a21a-4a5c4ee7fe2b"
      },
      "source": [
        "!pip install advertorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: advertorch in /usr/local/lib/python3.7/dist-packages (0.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd2jW6C2Nmea"
      },
      "source": [
        "import foolbox as fb\n",
        "from foolbox import PyTorchModel, accuracy, samples\n",
        "from foolbox.attacks import LinfPGD,LinfBasicIterativeAttack,LinfFastGradientAttack,L2CarliniWagnerAttack,LinfDeepFoolAttack,L2DeepFoolAttack"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moqsac7FMSyD"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import numpy as np\n",
        "import warnings\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from datetime import datetime\n",
        "import torchvision.models as models\n",
        "import urllib\n",
        "from advertorch.utils import predict_from_logits\n",
        "from advertorch_examples.utils import get_mnist_test_loader\n",
        "from advertorch_examples.utils import _imshow\n",
        "from advertorch.attacks import LinfPGDAttack,LinfBasicIterativeAttack\n",
        "from advertorch.bpda import BPDAWrapper\n",
        "from advertorch.defenses import MedianSmoothing2D\n",
        "from advertorch.defenses import BitSqueezing\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unfiy-1XdOIO"
      },
      "source": [
        "def zero_gradients(x):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        if x.grad is not None:\n",
        "            x.grad.detach_()\n",
        "            x.grad.zero_()\n",
        "    elif isinstance(x, collections.abc.Iterable):\n",
        "        for elem in x:\n",
        "            zero_gradients(elem)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaBnc3FnMcdF"
      },
      "source": [
        "class Model_Drop(nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Model_Drop, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3,padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3,padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3,padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3,padding=1)\n",
        "        self.fc1 = nn.Linear(7*7*64, 200)\n",
        "        self.fc2 = nn.Linear(200, 200)\n",
        "        self.fc3 = nn.Linear(200, 10)\n",
        "        self.drop_layer = nn.Dropout(p=0.50)\n",
        "\n",
        "    def last_hidden_layer_output(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
        "        x = x.view(-1, 7*7*64)\n",
        "        x = self.drop_layer((F.relu(self.fc1(x))))\n",
        "        x = self.drop_layer((F.relu(self.fc2(x))))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.last_hidden_layer_output(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjTeOrDeYFUh",
        "outputId": "42fbcfd5-e715-4827-8639-2e1b8d0287f7"
      },
      "source": [
        "print(\"Please chose reversal method you would like to test 0, 1, 2 :\\n Epistemic Uncertainty Based (0)\\n  Scibilic Uncertainty Based (1)\\n Scibilic Uncertainty Based (For Pred Class only) (2)\\n\")\n",
        "\n",
        "#input_a = int(input())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please chose reversal method you would like to test 0, 1, 2 :\n",
            " Epistemic Uncertainty Based (0)\n",
            "  Scibilic Uncertainty Based (1)\n",
            " Scibilic Uncertainty Based (For Pred Class only) (2)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmQDTa3PxKlK"
      },
      "source": [
        "def norms(Z):\n",
        "    \"\"\"Compute norms over all but the first dimension\"\"\"\n",
        "    return Z.view(Z.shape[0], -1).norm(dim=1)[:,None,None,None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdHxJYlYNs43"
      },
      "source": [
        "def unc_defense(image,model,epsilon, num_iter, alpha):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model((image+delta).clamp(0,1))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "\n",
        "        variance = torch.var(dropout_predictions, dim=0)\n",
        "\n",
        "        var = variance.mean(1,True)\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta).clamp(0, 1))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model((image + delta).clamp(0, 1))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "    model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeqYX8twXYst"
      },
      "source": [
        "def unc_defense_epistemic(image,model,epsilon, num_iter, alpha):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "    torch.cuda.manual_seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model((image+delta).clamp(0,1))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "        mean = torch.mean(dropout_predictions, dim=0)\n",
        "        pred_mean = mean\n",
        "\n",
        "        aleatoric = torch.zeros([item_count,10,10])\n",
        "        epistemic = torch.zeros([item_count,10,10])\n",
        "\n",
        "        for ti in range(50):\n",
        "\n",
        "            pred_t = dropout_predictions[ti]\n",
        "\n",
        "            aleatoric += torch.diag_embed(pred_t, offset=0, dim1=-2, dim2=-1) - pred_t[:, :, None] @ pred_t[:, None, :]\n",
        "            epistemic += (pred_t - pred_mean)[:, :, None] @ (pred_t - pred_mean)[:, None, :]\n",
        "\n",
        "\n",
        "        aleatoric = aleatoric / 50\n",
        "        epistemic = epistemic / 50\n",
        "\n",
        "        ep = epistemic.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "        al = aleatoric.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "\n",
        "        sc = ep / al\n",
        "  \n",
        "\n",
        "        var = ep\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta).clamp(0, 1))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model((image + delta).clamp(0, 1))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovelmveUyO2z"
      },
      "source": [
        "def unc_defense_scibilic(image,model,epsilon, num_iter, alpha):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "    torch.cuda.manual_seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model((image+delta).clamp(0,1))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "        mean = torch.mean(dropout_predictions, dim=0)\n",
        "        pred_mean = mean\n",
        "\n",
        "        aleatoric = torch.zeros([item_count,10,10])\n",
        "        epistemic = torch.zeros([item_count,10,10])\n",
        "\n",
        "        for ti in range(50):\n",
        "\n",
        "            pred_t = dropout_predictions[ti]\n",
        "\n",
        "            aleatoric += torch.diag_embed(pred_t, offset=0, dim1=-2, dim2=-1) - pred_t[:, :, None] @ pred_t[:, None, :]\n",
        "            epistemic += (pred_t - pred_mean)[:, :, None] @ (pred_t - pred_mean)[:, None, :]\n",
        "\n",
        "\n",
        "        aleatoric = aleatoric / 50\n",
        "        epistemic = epistemic / 50\n",
        "\n",
        "        ep = epistemic.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "        al = aleatoric.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "\n",
        "        sc = ep / al\n",
        "        \n",
        "        var = sc\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta).clamp(0, 1))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model((image + delta).clamp(0, 1))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHlIpPssAEeR"
      },
      "source": [
        "def unc_defense_scibilic_pred(image,model,epsilon, num_iter, alpha,preds):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "    torch.cuda.manual_seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    #image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model((image+delta).clamp(0,1))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "        mean = torch.mean(dropout_predictions, dim=0)\n",
        "        pred_mean = mean\n",
        "\n",
        "        aleatoric = torch.zeros([item_count,10,10])\n",
        "        epistemic = torch.zeros([item_count,10,10])\n",
        "\n",
        "        for ti in range(50):\n",
        "\n",
        "            pred_t = dropout_predictions[ti]\n",
        "\n",
        "            aleatoric += torch.diag_embed(pred_t, offset=0, dim1=-2, dim2=-1) - pred_t[:, :, None] @ pred_t[:, None, :]\n",
        "            epistemic += (pred_t - pred_mean)[:, :, None] @ (pred_t - pred_mean)[:, None, :]\n",
        "\n",
        "\n",
        "        aleatoric = aleatoric / 50\n",
        "        epistemic = epistemic / 50\n",
        "\n",
        "        preds = preds.to(device)\n",
        "        epistemic = epistemic.to(device)\n",
        "        aleatoric = aleatoric.to(device)\n",
        "\n",
        "        ep = epistemic.diagonal(dim1=-2, dim2=-1).gather(1, preds.unsqueeze(1))\n",
        "        al = aleatoric.diagonal(dim1=-2, dim2=-1).gather(1, preds.unsqueeze(1))\n",
        "\n",
        "        sc = ep / al\n",
        "\n",
        "        var = sc\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta).clamp(0, 1))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            #print(torch.count_nonzero(delta_unc)/delta_unc.shape[0])\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model((image + delta).clamp(0, 1))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            #print(torch.count_nonzero(delta_unc)/delta_unc.shape[0])\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGvtPNysCT0p"
      },
      "source": [
        "def pgd(image,model,epsilon, label, alpha, num_iter, restarts):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "    image = image.detach()\n",
        "\n",
        "    max_loss = torch.zeros(label.shape[0]).to(label.device)\n",
        "    max_delta = torch.zeros_like(image)\n",
        "\n",
        "    for i in range(restarts):\n",
        "\n",
        "        delta = torch.rand_like(image, requires_grad=True)\n",
        "        delta.data = delta.data * 2 * epsilon - epsilon\n",
        "\n",
        "        for t in range(num_iter):\n",
        "\n",
        "            model.eval()\n",
        "            o = model((image + delta))\n",
        "\n",
        "            loss = nn.CrossEntropyLoss(reduce=False)(o, label)\n",
        "            loss = loss.reshape(1, item_count)\n",
        "\n",
        "            loss.backward(torch.ones_like(loss))\n",
        "\n",
        "            delta.data = (delta + alpha * delta.grad.detach().sign()).clamp(-epsilon, epsilon)\n",
        "            delta.grad.zero_()\n",
        "        \n",
        "        all_loss = nn.CrossEntropyLoss(reduction='none')(model((image + delta)),label)\n",
        "        max_delta[all_loss >= max_loss] = delta.detach()[all_loss >= max_loss]\n",
        "        max_loss = torch.max(max_loss, all_loss)\n",
        "\n",
        "\n",
        "    perturbed_image = image + max_delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cegubmYQDgmg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3acc082-e79c-40eb-dfbf-0de7b664a611"
      },
      "source": [
        "!git clone https://github.com/knamdar/data.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'data' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFcxfzsikYWL"
      },
      "source": [
        "def norms(Z):\n",
        "    \"\"\"Compute norms over all but the first dimension\"\"\"\n",
        "    return Z.view(Z.shape[0], -1).norm(dim=1)[:,None,None,None]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcCTWpJeMhmH"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "torch.manual_seed(2)\n",
        "np.random.seed(2)\n",
        "\n",
        "batch_size = 64\n",
        "eps = 0.10\n",
        "alpha = 0.2 * eps\n",
        "num_iter = 10\n",
        "eps_l2 = 1.35\n",
        "\n",
        "\n",
        "eps_little = 0.2 * eps\n",
        "alpha_reverse = 0.2 * eps_little\n",
        "num_iter_reverse = 20\n",
        "\n",
        "count_successful_reverse = 0\n",
        "count_unsuccessful_reverse = 0\n",
        "\n",
        "count_successfull_attack = 0\n",
        "count_unsuccessfull_attack = 0\n",
        "\n",
        "test_data = datasets.MNIST(root='data', train=False, download=False, transform=transforms.ToTensor())\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwKm-A1gM1ZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fec9be6-4bae-47ab-f68f-aa25910356a7"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "cuda = \"cuda\"\n",
        "cpu = \"cpu\"\n",
        "devices = (cpu, cuda) if torch.cuda.is_available() else (cpu, )\n",
        "\n",
        "model_cnn_student = Model_Drop()\n",
        "model_cnn_student.load_state_dict(torch.load(\"/content/gdrive/MyDrive/TENET_DIGIT_MNIST_model_cnn_student_T_20.pt\",map_location=device))\n",
        "model_cnn_student.eval()\n",
        "model_cnn_student.to(device)\n",
        "\n",
        "#TENET_DIGIT_MNIST_model_cnn_student_T_20\n",
        "#TENET_DIGIT_MNIST_model_cnn_normal\n",
        "\n",
        "#model_cnn_normal = Model_Drop()\n",
        "#model_cnn_normal.load_state_dict(torch.load(\"/content/gdrive/MyDrive/TENET_DIGIT_MNIST_model_cnn_normal.pt\",map_location=device))\n",
        "#model_cnn_normal.eval()\n",
        "#model_cnn_normal.to(device)\n",
        "\n",
        "#model_cnn.load_state_dict(torch.load(\"model_cnn_mnist_robust.pt\",map_location=device))\n",
        "#model_cnn.load_state_dict(torch.load(\"model_cnn_mnist_normal.pt\",map_location=device))\n",
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "def enable_dropout(model):\n",
        "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
        "    for m in model.modules():\n",
        "        if m.__class__.__name__.startswith('Dropout'):\n",
        "            m.train()\n",
        "\n",
        "corrects = []\n",
        "corrects_tuple_list = []\n",
        "\n",
        "reformatted_GMT_timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "print(reformatted_GMT_timestamp)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-22 06:45:27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbpPlDdncwIu"
      },
      "source": [
        " torch.__version__\n",
        " input_a = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go6C5yBDM5AC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2969592a-45a4-457a-fbea-cb7d7a357d25"
      },
      "source": [
        "\n",
        "\n",
        "bits_squeezing = BitSqueezing(bit_depth=5)\n",
        "median_filter = MedianSmoothing2D(kernel_size=3)\n",
        "\n",
        "defense = nn.Sequential(\n",
        "    bits_squeezing,\n",
        "    median_filter,\n",
        ")\n",
        "\n",
        "defense = defense.to(device)\n",
        "\n",
        "defense_withbpda = BPDAWrapper(defense, forwardsub=lambda x: x)\n",
        "defended_model = nn.Sequential(defense_withbpda, model_cnn_student)\n",
        "defended_model = defended_model.to(device)\n",
        "defended_model = defended_model.eval()\n",
        "\n",
        "for i, (image, label) in enumerate(test_loader):\n",
        "\n",
        "    if i% 25 == 0:\n",
        "      print(\"i is \",i)\n",
        "\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    model_cnn_student.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn_student(image)\n",
        "        o = softmax(o)\n",
        "\n",
        "    pred_original = o.data.max(1, keepdim=True)[1]\n",
        "    pred_original = pred_original.view_as(label)\n",
        "    inds_correct = np.where(pred_original.cpu() == label.cpu())[0]\n",
        "\n",
        "    image = image[inds_correct]\n",
        "    label = label[inds_correct]\n",
        "\n",
        "    pert = pgd(image,model_cnn_student,eps, label, 0.03, 40, 5)\n",
        "\n",
        "    model_cnn_student.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn_student(pert)\n",
        "        o = softmax(o)\n",
        "    pred_pert = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    pred_pert = pred_pert.view_as(label)\n",
        "\n",
        "    inds_correct_after_attack = np.where(pred_pert.cpu() == label.cpu())[0]\n",
        "    inds_wrong_after_attack = np.where(pred_pert.cpu() != label.cpu())[0]\n",
        "\n",
        "\n",
        "    if inds_wrong_after_attack.shape[0] == 0:\n",
        "        print(\"no successful attack at ith batch ,where i = \", i)\n",
        "        continue\n",
        "\n",
        "    image = image[inds_wrong_after_attack]\n",
        "    label = label[inds_wrong_after_attack]\n",
        "    pert = pert[inds_wrong_after_attack]\n",
        "    pred_pert = pred_pert[inds_wrong_after_attack]\n",
        "\n",
        "    if input_a == 0:\n",
        "      reversed_pert = unc_defense_epistemic(pert, model_cnn_student, eps_little, num_iter_reverse, alpha_reverse)\n",
        "    elif input_a == 1:\n",
        "      reversed_pert = unc_defense_scibilic(pert, model_cnn_student, eps_little, num_iter_reverse, alpha_reverse)\n",
        "    elif input_a == 2:\n",
        "      reversed_pert = unc_defense_scibilic_pred(pert, model_cnn_student, eps_little, num_iter_reverse, alpha_reverse,pred_pert)\n",
        "\n",
        "    model_cnn_student.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn_student(reversed_pert)\n",
        "        o = softmax(o)\n",
        "    pred_reverse = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    pred_reverse = pred_reverse.view_as(label)\n",
        "\n",
        "    inds_correct_after_reverse = np.where(pred_reverse.cpu() == label.cpu())[0]\n",
        "    inds_wrong_after_reverse = np.where(pred_reverse.cpu() != label.cpu())[0]\n",
        "\n",
        "    reversed_pert = reversed_pert[inds_correct_after_reverse]\n",
        "    image = image[inds_correct_after_reverse]\n",
        "    label = label[inds_correct_after_reverse]\n",
        "    pert = pert[inds_correct_after_reverse]\n",
        "    pred_pert = pred_pert[inds_correct_after_reverse]\n",
        "\n",
        "    inds_correct_after_reverse = inds_correct_after_reverse.tolist()\n",
        "    inds_wrong_after_reverse = inds_wrong_after_reverse.tolist()\n",
        "\n",
        "    count_successful_reverse += len(inds_correct_after_reverse)\n",
        "    count_unsuccessful_reverse += len(inds_wrong_after_reverse)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i is  0\n",
            "no successful attack at ith batch ,where i =  3\n",
            "no successful attack at ith batch ,where i =  4\n",
            "no successful attack at ith batch ,where i =  8\n",
            "no successful attack at ith batch ,where i =  10\n",
            "i is  25\n",
            "no successful attack at ith batch ,where i =  28\n",
            "no successful attack at ith batch ,where i =  30\n",
            "no successful attack at ith batch ,where i =  32\n",
            "no successful attack at ith batch ,where i =  40\n",
            "no successful attack at ith batch ,where i =  41\n",
            "no successful attack at ith batch ,where i =  43\n",
            "no successful attack at ith batch ,where i =  45\n",
            "i is  50\n",
            "no successful attack at ith batch ,where i =  64\n",
            "no successful attack at ith batch ,where i =  68\n",
            "no successful attack at ith batch ,where i =  69\n",
            "i is  75\n",
            "no successful attack at ith batch ,where i =  76\n",
            "no successful attack at ith batch ,where i =  78\n",
            "no successful attack at ith batch ,where i =  79\n",
            "no successful attack at ith batch ,where i =  80\n",
            "no successful attack at ith batch ,where i =  82\n",
            "no successful attack at ith batch ,where i =  84\n",
            "no successful attack at ith batch ,where i =  86\n",
            "no successful attack at ith batch ,where i =  87\n",
            "no successful attack at ith batch ,where i =  90\n",
            "no successful attack at ith batch ,where i =  91\n",
            "no successful attack at ith batch ,where i =  94\n",
            "no successful attack at ith batch ,where i =  97\n",
            "no successful attack at ith batch ,where i =  98\n",
            "no successful attack at ith batch ,where i =  99\n",
            "i is  100\n",
            "no successful attack at ith batch ,where i =  101\n",
            "no successful attack at ith batch ,where i =  103\n",
            "no successful attack at ith batch ,where i =  104\n",
            "no successful attack at ith batch ,where i =  106\n",
            "no successful attack at ith batch ,where i =  107\n",
            "no successful attack at ith batch ,where i =  108\n",
            "no successful attack at ith batch ,where i =  109\n",
            "no successful attack at ith batch ,where i =  110\n",
            "no successful attack at ith batch ,where i =  111\n",
            "no successful attack at ith batch ,where i =  114\n",
            "no successful attack at ith batch ,where i =  115\n",
            "no successful attack at ith batch ,where i =  117\n",
            "no successful attack at ith batch ,where i =  118\n",
            "no successful attack at ith batch ,where i =  119\n",
            "no successful attack at ith batch ,where i =  120\n",
            "no successful attack at ith batch ,where i =  121\n",
            "no successful attack at ith batch ,where i =  122\n",
            "no successful attack at ith batch ,where i =  123\n",
            "no successful attack at ith batch ,where i =  124\n",
            "i is  125\n",
            "no successful attack at ith batch ,where i =  126\n",
            "no successful attack at ith batch ,where i =  128\n",
            "no successful attack at ith batch ,where i =  131\n",
            "no successful attack at ith batch ,where i =  132\n",
            "no successful attack at ith batch ,where i =  134\n",
            "no successful attack at ith batch ,where i =  135\n",
            "no successful attack at ith batch ,where i =  136\n",
            "no successful attack at ith batch ,where i =  137\n",
            "no successful attack at ith batch ,where i =  138\n",
            "no successful attack at ith batch ,where i =  139\n",
            "no successful attack at ith batch ,where i =  141\n",
            "no successful attack at ith batch ,where i =  142\n",
            "no successful attack at ith batch ,where i =  143\n",
            "no successful attack at ith batch ,where i =  144\n",
            "no successful attack at ith batch ,where i =  145\n",
            "no successful attack at ith batch ,where i =  146\n",
            "no successful attack at ith batch ,where i =  147\n",
            "no successful attack at ith batch ,where i =  149\n",
            "i is  150\n",
            "no successful attack at ith batch ,where i =  155\n",
            "no successful attack at ith batch ,where i =  156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-KlO9zTNWN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6d7caa5-863e-48bd-bc08-6ffea44d0792"
      },
      "source": [
        "print(\"Number of successful reverse operation is : \", count_successful_reverse)\n",
        "print(\"Number of unsuccessful reverse operation is : \", count_unsuccessful_reverse)\n",
        "\n",
        "reformatted_GMT_timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "print(reformatted_GMT_timestamp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successful reverse operation is :  4\n",
            "Number of unsuccessful reverse operation is :  181\n",
            "2021-11-22 06:57:25\n"
          ]
        }
      ]
    }
  ]
}