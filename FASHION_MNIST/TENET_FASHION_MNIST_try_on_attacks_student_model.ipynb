{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TENET_FASHION_MNIST_try_on_attacks_student_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "awZ-vXCYt801",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e96f3944-40c1-45f7-9a82-3f35b777e871"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVpBTrQEuCDy"
      },
      "source": [
        "#!ls \"/content/gdrive/MyDrive/\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq672y9uNbTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29ae62c5-039b-49d3-f546-5a84ca3a7094"
      },
      "source": [
        "!pip install foolbox"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: foolbox in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.4.1)\n",
            "Requirement already satisfied: eagerpy==0.29.0 in /usr/local/lib/python3.7/dist-packages (from foolbox) (0.29.0)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.7/dist-packages (from foolbox) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.7/dist-packages (from foolbox) (3.7.4.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from foolbox) (57.0.0)\n",
            "Requirement already satisfied: GitPython>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from foolbox) (3.1.18)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.19.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (3.0.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=3.0.7->foolbox) (4.0.7)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox) (4.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd2jW6C2Nmea"
      },
      "source": [
        "import foolbox as fb\n",
        "from foolbox import PyTorchModel, accuracy, samples\n",
        "from foolbox.attacks import LinfPGD,LinfBasicIterativeAttack,LinfFastGradientAttack,L2CarliniWagnerAttack,LinfDeepFoolAttack,L2DeepFoolAttack"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moqsac7FMSyD"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import numpy as np\n",
        "import warnings\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from datetime import datetime\n",
        "import torchvision.models as models\n",
        "import urllib\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaBnc3FnMcdF"
      },
      "source": [
        "class Model_Drop(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model_Drop, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3,padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3,padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3,padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3,padding=1)\n",
        "        self.fc1 = nn.Linear(7*7*64, 600)\n",
        "        self.fc2 = nn.Linear(600, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "        self.drop_layer = nn.Dropout(p=0.25)\n",
        "\n",
        "    def last_hidden_layer_output(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = self.drop_layer(F.relu(self.conv3(x)))\n",
        "        x = self.drop_layer(F.relu(self.conv4(x)))\n",
        "        x = x.view(-1, 7*7*64)\n",
        "        x = self.drop_layer(F.relu(self.fc1(x)))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.last_hidden_layer_output(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjTeOrDeYFUh",
        "outputId": "69b109e7-c70a-4936-fe2e-0ea464be234f"
      },
      "source": [
        "print(\"Please chose reversal method you would like to test 0, 1, 2 :\\n Epistemic Uncertainty Based (0)\\n  Scibilic Uncertainty Based (1)\\n Scibilic Uncertainty Based (For Pred Class only) (2)\\n\")\n",
        "\n",
        "input_a = int(input())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please chose reversal method you would like to test 0, 1, 2 :\n",
            " Epistemic Uncertainty Based (0)\n",
            "  Scibilic Uncertainty Based (1)\n",
            " Scibilic Uncertainty Based (For Pred Class only) (2)\n",
            "\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmQDTa3PxKlK"
      },
      "source": [
        "def norms(Z):\n",
        "    \"\"\"Compute norms over all but the first dimension\"\"\"\n",
        "    return Z.view(Z.shape[0], -1).norm(dim=1)[:,None,None,None]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdHxJYlYNs43"
      },
      "source": [
        "def unc_defense(image,model,epsilon, num_iter, alpha):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model((image+delta).clamp(0,1))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "\n",
        "        variance = torch.var(dropout_predictions, dim=0)\n",
        "\n",
        "        var = variance.mean(1,True)\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta).clamp(0, 1))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "            #delta.data -= alpha * delta_unc / (norms(delta_unc) + 1e-30)\n",
        "            #delta.data = torch.min(torch.max(delta.detach(), -image), 1 - image)  # clip X+delta to [0,1]\n",
        "            #delta.data *= epsilon / norms(delta.detach()).clamp(min=epsilon)\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model((image + delta).clamp(0, 1))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "            #delta.data -= alpha * delta_unc / (norms(delta_unc) + 1e-30)\n",
        "            #delta.data = torch.min(torch.max(delta.detach(), -image), 1 - image)  # clip X+delta to [0,1]\n",
        "            #delta.data *= epsilon / norms(delta.detach()).clamp(min=epsilon)\n",
        "\n",
        "    model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeqYX8twXYst"
      },
      "source": [
        "def unc_defense_epistemic(image,model,epsilon, num_iter, alpha):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "    torch.cuda.manual_seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model((image+delta).clamp(0,1))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "        mean = torch.mean(dropout_predictions, dim=0)\n",
        "        pred_mean = mean\n",
        "\n",
        "        aleatoric = torch.zeros([item_count,10,10])\n",
        "        epistemic = torch.zeros([item_count,10,10])\n",
        "\n",
        "        for ti in range(50):\n",
        "\n",
        "            pred_t = dropout_predictions[ti]\n",
        "\n",
        "            aleatoric += torch.diag_embed(pred_t, offset=0, dim1=-2, dim2=-1) - pred_t[:, :, None] @ pred_t[:, None, :]\n",
        "            epistemic += (pred_t - pred_mean)[:, :, None] @ (pred_t - pred_mean)[:, None, :]\n",
        "\n",
        "\n",
        "        aleatoric = aleatoric / 50\n",
        "        epistemic = epistemic / 50\n",
        "\n",
        "        ep = epistemic.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "        al = aleatoric.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "\n",
        "        sc = ep / al\n",
        "  \n",
        "\n",
        "        var = ep\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta).clamp(0, 1))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model((image + delta).clamp(0, 1))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "            #delta.data -= alpha * delta_unc / (norms(delta_unc) + 1e-30)\n",
        "            #delta.data = torch.min(torch.max(delta.detach(), -image), 1 - image)  # clip X+delta to [0,1]\n",
        "            #delta.data *= epsilon / norms(delta.detach()).clamp(min=epsilon)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovelmveUyO2z"
      },
      "source": [
        "def unc_defense_scibilic(image,model,epsilon, num_iter, alpha):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "    torch.cuda.manual_seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model((image+delta).clamp(0,1))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "        mean = torch.mean(dropout_predictions, dim=0)\n",
        "        pred_mean = mean\n",
        "\n",
        "        aleatoric = torch.zeros([item_count,10,10])\n",
        "        epistemic = torch.zeros([item_count,10,10])\n",
        "\n",
        "        for ti in range(50):\n",
        "\n",
        "            pred_t = dropout_predictions[ti]\n",
        "\n",
        "            aleatoric += torch.diag_embed(pred_t, offset=0, dim1=-2, dim2=-1) - pred_t[:, :, None] @ pred_t[:, None, :]\n",
        "            epistemic += (pred_t - pred_mean)[:, :, None] @ (pred_t - pred_mean)[:, None, :]\n",
        "\n",
        "\n",
        "        aleatoric = aleatoric / 50\n",
        "        epistemic = epistemic / 50\n",
        "\n",
        "        ep = epistemic.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "        al = aleatoric.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "\n",
        "        sc = ep / al\n",
        "        #sc = al / ep\n",
        "\n",
        "        var = sc\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta).clamp(0, 1))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model((image + delta).clamp(0, 1))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "            #delta.data -= alpha * delta_unc / (norms(delta_unc) + 1e-30)\n",
        "            #delta.data = torch.min(torch.max(delta.detach(), -image), 1 - image)  # clip X+delta to [0,1]\n",
        "            #delta.data *= epsilon / norms(delta.detach()).clamp(min=epsilon)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHlIpPssAEeR"
      },
      "source": [
        "def unc_defense_scibilic_pred(image,model,epsilon, num_iter, alpha,preds):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "    torch.cuda.manual_seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model((image+delta).clamp(0,1))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "        mean = torch.mean(dropout_predictions, dim=0)\n",
        "        pred_mean = mean\n",
        "\n",
        "        aleatoric = torch.zeros([item_count,10,10])\n",
        "        epistemic = torch.zeros([item_count,10,10])\n",
        "\n",
        "        for ti in range(50):\n",
        "\n",
        "            pred_t = dropout_predictions[ti]\n",
        "\n",
        "\n",
        "            #print(\"item_count\",item_count)\n",
        "            #print(\"pred_t shape\", pred_t.shape)\n",
        "            #print(\"aleatoric shape\", aleatoric.shape)\n",
        "            #print(\"squezed shape\", squezed_pred_t.shape)\n",
        "            #print(\"outer product shape\", (pred_t[:, :, None] @ pred_t[:, None, :]).shape)\n",
        "            #print(\"diag size is \", torch.diag_embed(pred_t, offset=0, dim1=-2, dim2=-1).shape)\n",
        "\n",
        "            aleatoric += torch.diag_embed(pred_t, offset=0, dim1=-2, dim2=-1) - pred_t[:, :, None] @ pred_t[:, None, :]\n",
        "            epistemic += (pred_t - pred_mean)[:, :, None] @ (pred_t - pred_mean)[:, None, :]\n",
        "\n",
        "\n",
        "        aleatoric = aleatoric / 50\n",
        "        epistemic = epistemic / 50\n",
        "\n",
        "        preds = preds.to(device)\n",
        "        epistemic = epistemic.to(device)\n",
        "        aleatoric = aleatoric.to(device)\n",
        "\n",
        "        ep = epistemic.diagonal(dim1=-2, dim2=-1).gather(1, preds.unsqueeze(1))\n",
        "        al = aleatoric.diagonal(dim1=-2, dim2=-1).gather(1, preds.unsqueeze(1))\n",
        "\n",
        "        #ep = epistemic.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "        #al = aleatoric.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "\n",
        "        sc = ep / al\n",
        "        #sc = al / ep\n",
        "\n",
        "        var = sc\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta).clamp(0, 1))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            #print(torch.count_nonzero(delta_unc)/delta_unc.shape[0])\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "            #delta.data -= alpha * delta_unc / (norms(delta_unc) + 1e-30)\n",
        "            #delta.data = torch.min(torch.max(delta.detach(), -image), 1 - image)  # clip X+delta to [0,1]\n",
        "            #delta.data *= epsilon / norms(delta.detach()).clamp(min=epsilon)\n",
        "\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model((image + delta).clamp(0, 1))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            #print(torch.count_nonzero(delta_unc)/delta_unc.shape[0])\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "            #delta.data -= alpha * delta_unc / (norms(delta_unc) + 1e-30)\n",
        "            #delta.data = torch.min(torch.max(delta.detach(), -image), 1 - image)  # clip X+delta to [0,1]\n",
        "            #delta.data *= epsilon / norms(delta.detach()).clamp(min=epsilon)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cegubmYQDgmg"
      },
      "source": [
        "#!git clone https://github.com/knamdar/data.git\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFcxfzsikYWL"
      },
      "source": [
        "def norms(Z):\n",
        "    \"\"\"Compute norms over all but the first dimension\"\"\"\n",
        "    return Z.view(Z.shape[0], -1).norm(dim=1)[:,None,None,None]\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcCTWpJeMhmH"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "torch.manual_seed(2)\n",
        "np.random.seed(2)\n",
        "\n",
        "batch_size = 64\n",
        "eps = 0.03\n",
        "alpha = 0.2 * eps\n",
        "num_iter = 10\n",
        "eps_l2 = 0.4032\n",
        "\n",
        "eps_little = 0.2 * eps\n",
        "alpha_reverse = 0.2 * eps_little\n",
        "num_iter_reverse = 10\n",
        "\n",
        "count_successful_reverse = 0\n",
        "count_unsuccessful_reverse = 0\n",
        "\n",
        "count_successfull_attack = 0\n",
        "count_unsuccessfull_attack = 0\n",
        "\n",
        "test_data = datasets.FashionMNIST(root='data', train=False, download=True, transform=transforms.ToTensor())\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwKm-A1gM1ZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b08b6d5-6722-4eaa-a4eb-76826d959dec"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#model_cnn_teacher = Model_Drop()\n",
        "#model_cnn_teacher.load_state_dict(torch.load(\"/content/gdrive/MyDrive/TENET_FASHION_MNIST_model_cnn_teacher_T_100.pt\",map_location=device))\n",
        "#model_cnn_teacher.eval()\n",
        "#model_cnn_teacher.to(device)\n",
        "\n",
        "#model_cnn_student = Model_Drop()\n",
        "#model_cnn_student.load_state_dict(torch.load(\"/content/gdrive/MyDrive/TENET_FASHION_MNIST_model_cnn_student_T_100.pt\",map_location=device))\n",
        "#model_cnn_student.eval()\n",
        "#model_cnn_student.to(device)\n",
        "\n",
        "\n",
        "model_cnn_normal = Model_Drop()\n",
        "model_cnn_normal.load_state_dict(torch.load(\"/content/gdrive/MyDrive/TENET_FASHION_MNIST_model_cnn_student_T_100.pt\",map_location=device))\n",
        "model_cnn_normal.eval()\n",
        "model_cnn_normal.to(device)\n",
        "\n",
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "def enable_dropout(model):\n",
        "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
        "    for m in model.modules():\n",
        "        if m.__class__.__name__.startswith('Dropout'):\n",
        "            m.train()\n",
        "\n",
        "corrects = []\n",
        "corrects_tuple_list = []\n",
        "\n",
        "reformatted_GMT_timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "print(reformatted_GMT_timestamp)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-04 21:35:53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RbpPlDdncwIu",
        "outputId": "ab1d1898-6c1f-4604-fd5f-e86043f5377f"
      },
      "source": [
        " torch.__version__"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.9.0+cu102'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go6C5yBDM5AC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7fba4a5-2502-4970-915a-73cf8c9e7840"
      },
      "source": [
        "for i, (image, label) in enumerate(test_loader):\n",
        "\n",
        "    if i% 25 == 0:\n",
        "      print(\"i is \",i)\n",
        "\n",
        "\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    model_cnn_normal.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn_normal(image)\n",
        "        o = softmax(o)\n",
        "\n",
        "    pred_original = o.data.max(1, keepdim=True)[1]\n",
        "    pred_original = pred_original.view_as(label)\n",
        "    inds_correct = np.where(pred_original.cpu() == label.cpu())[0]\n",
        "\n",
        "    image = image[inds_correct]\n",
        "    label = label[inds_correct]\n",
        "\n",
        "\n",
        "    #attack = LinfDeepFoolAttack()\n",
        "    #fmodel = PyTorchModel(model_cnn_normal, bounds=(0, 1))\n",
        "    #raw_advs, clipped_advs, success = attack(fmodel, image, label, epsilons=[eps])\n",
        "    #pert = torch.tensor(clipped_advs[0])\n",
        "\n",
        "    attack = L2CarliniWagnerAttack(steps=1000, confidence = 40)\n",
        "    fmodel = PyTorchModel(model_cnn_normal, bounds=(0, 1))\n",
        "    raw_advs, clipped_advs, success = attack(fmodel, image, label, epsilons=[eps_l2])\n",
        "    pert = torch.tensor(clipped_advs[0])\n",
        "\n",
        "    #attack = LinfBasicIterativeAttack()\n",
        "    #fmodel = PyTorchModel(model_cnn_normal, bounds=(0, 1))\n",
        "    #raw_advs, clipped_advs, success = attack(fmodel, image, label, epsilons=[eps])\n",
        "    #pert = torch.tensor(clipped_advs[0])\n",
        "\n",
        "    #attack = LinfPGD()\n",
        "    #fmodel = PyTorchModel(model_cnn_normal, bounds=(0, 1))\n",
        "    #raw_advs, clipped_advs, success = attack(fmodel, image, label, epsilons=[eps])\n",
        "    #pert = torch.tensor(clipped_advs[0])\n",
        "\n",
        "    #attack = LinfFastGradientAttack()\n",
        "    #fmodel = PyTorchModel(model_cnn_normal, bounds=(0, 1))\n",
        "    #raw_advs, clipped_advs, success = attack(fmodel, image, label, epsilons=[eps])\n",
        "    #pert = torch.tensor(clipped_advs[0])\n",
        "\n",
        "    #attack = L2DeepFoolAttack()\n",
        "    #fmodel = PyTorchModel(model_cnn_normal, bounds=(0, 1))\n",
        "    #raw_advs, clipped_advs, success = attack(fmodel, image, label, epsilons=[eps_l2])\n",
        "    #pert = torch.tensor(clipped_advs[0])\n",
        "\n",
        "    # pert = image\n",
        "\n",
        "    model_cnn_normal.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn_normal(pert)\n",
        "        o = softmax(o)\n",
        "    pred_pert = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    pred_pert = pred_pert.view_as(label)\n",
        "\n",
        "    inds_correct_after_attack = np.where(pred_pert.cpu() == label.cpu())[0]\n",
        "    inds_wrong_after_attack = np.where(pred_pert.cpu() != label.cpu())[0]\n",
        "\n",
        "\n",
        "    if inds_wrong_after_attack.shape[0] == 0:\n",
        "        print(\"no successful attack at ith batch ,where i = \", i)\n",
        "        continue\n",
        "\n",
        "    image = image[inds_wrong_after_attack]\n",
        "    label = label[inds_wrong_after_attack]\n",
        "    pert = pert[inds_wrong_after_attack]\n",
        "    pred_pert = pred_pert[inds_wrong_after_attack]\n",
        "\n",
        "    #reversed_pert = unc_defense(pert, model_cnn_normal, eps_little, num_iter_reverse, alpha_reverse)\n",
        "\n",
        "    if input_a == 0:\n",
        "      reversed_pert = unc_defense_epistemic(pert, model_cnn_normal, eps_little, num_iter_reverse, alpha_reverse)\n",
        "    elif input_a == 1:\n",
        "      reversed_pert = unc_defense_scibilic(pert, model_cnn_normal, eps_little, num_iter_reverse, alpha_reverse)\n",
        "    elif input_a == 2:\n",
        "      reversed_pert = unc_defense_scibilic_pred(pert, model_cnn_normal, eps_little, num_iter_reverse, alpha_reverse,pred_pert)\n",
        "\n",
        "    model_cnn_normal.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn_normal(reversed_pert)\n",
        "        o = softmax(o)\n",
        "    pred_reverse = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    pred_reverse = pred_reverse.view_as(label)\n",
        "\n",
        "    inds_correct_after_reverse = np.where(pred_reverse.cpu() == label.cpu())[0]\n",
        "    inds_wrong_after_reverse = np.where(pred_reverse.cpu() != label.cpu())[0]\n",
        "\n",
        "    reversed_pert = reversed_pert[inds_correct_after_reverse]\n",
        "    image = image[inds_correct_after_reverse]\n",
        "    label = label[inds_correct_after_reverse]\n",
        "    pert = pert[inds_correct_after_reverse]\n",
        "    pred_pert = pred_pert[inds_correct_after_reverse]\n",
        "\n",
        "    inds_correct_after_reverse = inds_correct_after_reverse.tolist()\n",
        "    inds_wrong_after_reverse = inds_wrong_after_reverse.tolist()\n",
        "\n",
        "    count_successful_reverse += len(inds_correct_after_reverse)\n",
        "    count_unsuccessful_reverse += len(inds_wrong_after_reverse)\n",
        "\n",
        "    #if i >= 2:\n",
        "      #break\n",
        "    \n",
        "    #if i%10 == 0:\n",
        "      #print(i)\n",
        "      #break\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i is  0\n",
            "i is  25\n",
            "i is  50\n",
            "i is  75\n",
            "i is  100\n",
            "i is  125\n",
            "i is  150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-KlO9zTNWN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34651927-e573-4eeb-81d8-17f10ef42d99"
      },
      "source": [
        "print(\"Number of successful reverse operation is : \", count_successful_reverse)\n",
        "print(\"Number of unsuccessful reverse operation is : \", count_unsuccessful_reverse)\n",
        "\n",
        "reformatted_GMT_timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "print(reformatted_GMT_timestamp)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of successful reverse operation is :  8328\n",
            "Number of unsuccessful reverse operation is :  13\n",
            "2021-07-04 23:11:22\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}