{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TENET_CIFAR10_try_on_corrects_normal_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmOzglIRDfVs",
        "outputId": "dd8d17e4-52f6-4836-e99d-e8133add4edf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3FaqGjiDjEi"
      },
      "source": [
        "#!ls \"/content/gdrive/MyDrive/\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZxyRd3mkmYJ"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import numpy as np\n",
        "import warnings\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from datetime import datetime\n",
        "import torchvision.models as models"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liOF1Yzbk3yg"
      },
      "source": [
        "class Model_Drop(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Model_Drop, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(4096, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "        self.drop_layer = nn.Dropout(p=0.5)\n",
        "        self.drop_layer_conv = nn.Dropout2d(p=0.5)\n",
        "\n",
        "    def last_hidden_layer_output(self, x):\n",
        "\n",
        "        x = F.relu(self.conv1(x),inplace=True)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x),inplace=True), kernel_size=2, stride=2)\n",
        "\n",
        "        x = F.relu(self.conv3(x),inplace=True)\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x),inplace=True), kernel_size=2, stride=2)\n",
        "\n",
        "        x = F.relu(self.conv5(x),inplace=True)\n",
        "        x = self.drop_layer_conv(F.max_pool2d(F.relu(self.conv6(x),inplace=True), kernel_size=2, stride=2))\n",
        "\n",
        "        x = x.view(-1, 4096)\n",
        "        x = self.drop_layer(F.relu(self.fc1(x)))\n",
        "        x = self.drop_layer(F.relu(self.fc2(x)))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.last_hidden_layer_output(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_prs4zHwI75y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b6e7dfd-e64f-4419-ccfc-f1f5e9c15498"
      },
      "source": [
        "print(\"Please chose reversal method you would like to test 0, 1, 2 :\\n Epistemic Uncertainty Based (0)\\n  Scibilic Uncertainty Based (1)\\n Scibilic Uncertainty Based (For Pred Class only) (2)\\n\")\n",
        "\n",
        "input_a = int(input())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please chose reversal method you would like to test 0, 1, 2 :\n",
            " Epistemic Uncertainty Based (0)\n",
            "  Scibilic Uncertainty Based (1)\n",
            " Scibilic Uncertainty Based (For Pred Class only) (2)\n",
            "\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkaC3xUqk6Jh"
      },
      "source": [
        "def unc_defense(image,model,epsilon, num_iter, alpha):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model((image+delta).clamp(0,1))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "\n",
        "        variance = torch.var(dropout_predictions, dim=0)\n",
        "\n",
        "        var = variance.mean(1,True)\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta).clamp(0, 1))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model((image + delta).clamp(0, 1))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIkn759FIuCs"
      },
      "source": [
        "def unc_defense_epistemic(image,model,epsilon, num_iter, alpha):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "    torch.cuda.manual_seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model((image+delta).clamp(0,1))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "        mean = torch.mean(dropout_predictions, dim=0)\n",
        "        pred_mean = mean\n",
        "\n",
        "        aleatoric = torch.zeros([item_count,10,10])\n",
        "        epistemic = torch.zeros([item_count,10,10])\n",
        "\n",
        "        for ti in range(50):\n",
        "\n",
        "            pred_t = dropout_predictions[ti]\n",
        "\n",
        "            aleatoric += torch.diag_embed(pred_t, offset=0, dim1=-2, dim2=-1) - pred_t[:, :, None] @ pred_t[:, None, :]\n",
        "            epistemic += (pred_t - pred_mean)[:, :, None] @ (pred_t - pred_mean)[:, None, :]\n",
        "\n",
        "\n",
        "        aleatoric = aleatoric / 50\n",
        "        epistemic = epistemic / 50\n",
        "\n",
        "        ep = epistemic.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "        al = aleatoric.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "\n",
        "        sc = ep / al\n",
        "  \n",
        "\n",
        "        var = ep\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta).clamp(0, 1))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model((image + delta).clamp(0, 1))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "            #delta.data -= alpha * delta_unc / (norms(delta_unc) + 1e-30)\n",
        "            #delta.data = torch.min(torch.max(delta.detach(), -image), 1 - image)  # clip X+delta to [0,1]\n",
        "            #delta.data *= epsilon / norms(delta.detach()).clamp(min=epsilon)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrFweMkJ-UNy"
      },
      "source": [
        "def unc_defense_scibilic(image,model,epsilon, num_iter, alpha):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "    torch.cuda.manual_seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model((image+delta).clamp(0,1))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "        mean = torch.mean(dropout_predictions, dim=0)\n",
        "        pred_mean = mean\n",
        "\n",
        "        aleatoric = torch.zeros([item_count,10,10])\n",
        "        epistemic = torch.zeros([item_count,10,10])\n",
        "\n",
        "        for ti in range(50):\n",
        "\n",
        "            pred_t = dropout_predictions[ti]\n",
        "\n",
        "            aleatoric += torch.diag_embed(pred_t, offset=0, dim1=-2, dim2=-1) - pred_t[:, :, None] @ pred_t[:, None, :]\n",
        "            epistemic += (pred_t - pred_mean)[:, :, None] @ (pred_t - pred_mean)[:, None, :]\n",
        "\n",
        "\n",
        "        aleatoric = aleatoric / 50\n",
        "        epistemic = epistemic / 50\n",
        "\n",
        "        ep = epistemic.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "        al = aleatoric.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "\n",
        "        sc = ep / al\n",
        "        #sc = al / ep\n",
        "\n",
        "        var = sc\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta).clamp(0, 1))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model((image + delta).clamp(0, 1))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "            #delta.data -= alpha * delta_unc / (norms(delta_unc) + 1e-30)\n",
        "            #delta.data = torch.min(torch.max(delta.detach(), -image), 1 - image)  # clip X+delta to [0,1]\n",
        "            #delta.data *= epsilon / norms(delta.detach()).clamp(min=epsilon)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyaAPiJWP_4d"
      },
      "source": [
        "def unc_defense_scibilic_pred(image,model,epsilon, num_iter, alpha,preds):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "    torch.cuda.manual_seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model((image+delta).clamp(0,1))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "        mean = torch.mean(dropout_predictions, dim=0)\n",
        "        pred_mean = mean\n",
        "\n",
        "        aleatoric = torch.zeros([item_count,10,10])\n",
        "        epistemic = torch.zeros([item_count,10,10])\n",
        "\n",
        "        for ti in range(50):\n",
        "\n",
        "            pred_t = dropout_predictions[ti]\n",
        "\n",
        "\n",
        "            #print(\"item_count\",item_count)\n",
        "            #print(\"pred_t shape\", pred_t.shape)\n",
        "            #print(\"aleatoric shape\", aleatoric.shape)\n",
        "            #print(\"squezed shape\", squezed_pred_t.shape)\n",
        "            #print(\"outer product shape\", (pred_t[:, :, None] @ pred_t[:, None, :]).shape)\n",
        "            #print(\"diag size is \", torch.diag_embed(pred_t, offset=0, dim1=-2, dim2=-1).shape)\n",
        "\n",
        "            aleatoric += torch.diag_embed(pred_t, offset=0, dim1=-2, dim2=-1) - pred_t[:, :, None] @ pred_t[:, None, :]\n",
        "            epistemic += (pred_t - pred_mean)[:, :, None] @ (pred_t - pred_mean)[:, None, :]\n",
        "\n",
        "\n",
        "        aleatoric = aleatoric / 50\n",
        "        epistemic = epistemic / 50\n",
        "\n",
        "        preds = preds.to(device)\n",
        "        epistemic = epistemic.to(device)\n",
        "        aleatoric = aleatoric.to(device)\n",
        "\n",
        "\n",
        "        ep = epistemic.diagonal(dim1=-2, dim2=-1).gather(1, preds.unsqueeze(1))\n",
        "        al = aleatoric.diagonal(dim1=-2, dim2=-1).gather(1, preds.unsqueeze(1))\n",
        "\n",
        "        #ep = epistemic.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "        #al = aleatoric.diagonal(dim1=-2, dim2=-1)[:].mean(1)\n",
        "\n",
        "        sc = ep / al\n",
        "        #sc = al / ep\n",
        "\n",
        "        var = sc\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta).clamp(0, 1))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            #print(torch.count_nonzero(delta_unc)/delta_unc.shape[0])\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "            #delta.data -= alpha * delta_unc / (norms(delta_unc) + 1e-30)\n",
        "            #delta.data = torch.min(torch.max(delta.detach(), -image), 1 - image)  # clip X+delta to [0,1]\n",
        "            #delta.data *= epsilon / norms(delta.detach()).clamp(min=epsilon)\n",
        "\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model((image + delta).clamp(0, 1))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            #print(torch.count_nonzero(delta_unc)/delta_unc.shape[0])\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "            #delta.data -= alpha * delta_unc / (norms(delta_unc) + 1e-30)\n",
        "            #delta.data = torch.min(torch.max(delta.detach(), -image), 1 - image)  # clip X+delta to [0,1]\n",
        "            #delta.data *= epsilon / norms(delta.detach()).clamp(min=epsilon)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9nHaPjxk-Su",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98a2e7c-0173-46a7-9de5-f7f8f2462d24"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "torch.manual_seed(2)\n",
        "np.random.seed(2)\n",
        "torch.cuda.manual_seed(2)\n",
        "\n",
        "batch_size = 64\n",
        "eps = 4.0/255\n",
        "alpha = 0.2 * eps\n",
        "num_iter = 10\n",
        "eps_l2 = 0.42\n",
        "#eps_l2 = 2\n",
        "print(eps)\n",
        "\n",
        "#eps_little = 0.2*eps\n",
        "eps_little = 0.2/255\n",
        "alpha_reverse = 0.2 * eps_little\n",
        "num_iter_reverse = 10\n",
        "\n",
        "\n",
        "count_successful_reverse = 0\n",
        "count_unsuccessful_reverse = 0\n",
        "\n",
        "count_successfull_attack = 0\n",
        "count_unsuccessfull_attack = 0\n",
        "\n",
        "\n",
        "test_data = datasets.CIFAR10(root='data', train=False, download=True, transform=transforms.ToTensor())\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.01568627450980392\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKYU8kLvlBbs",
        "outputId": "ff601707-4bdb-4847-a1ad-2272b1fa5efc"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_cnn = Model_Drop()\n",
        "model_cnn.load_state_dict(torch.load(\"/content/gdrive/MyDrive/TENET_CIFAR10_model_cnn_normal.pt\",map_location=device))\n",
        "model_cnn.eval()\n",
        "model_cnn.to(device)\n",
        "\n",
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "def enable_dropout(model):\n",
        "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
        "    for m in model.modules():\n",
        "        if m.__class__.__name__.startswith('Dropout'):\n",
        "            m.train()\n",
        "\n",
        "corrects = []\n",
        "corrects_tuple_list = []\n",
        "\n",
        "reformatted_GMT_timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "print(reformatted_GMT_timestamp)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-02 15:55:09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26UWUseylEcr"
      },
      "source": [
        "for i, (image, label) in enumerate(test_loader):\n",
        "\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    pert = image\n",
        "\n",
        "    model_cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn(pert)\n",
        "        o = softmax(o)\n",
        "    pred_pert = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "\n",
        "    pred_pert = pred_pert.view_as(label)\n",
        "\n",
        "\n",
        "    inds_correct_after_attack = np.where(pred_pert.cpu() == label.cpu())[0]\n",
        "    inds_wrong_after_attack = np.where(pred_pert.cpu() != label.cpu())[0]\n",
        "\n",
        "\n",
        "    #if inds_wrong_after_attack.shape[0] == 0:\n",
        "      #continue\n",
        "\n",
        "\n",
        "    image = image[inds_correct_after_attack]\n",
        "    label = label[inds_correct_after_attack]\n",
        "    pert = pert[inds_correct_after_attack]\n",
        "    pred_pert = pred_pert[inds_correct_after_attack]\n",
        "\n",
        "    if input_a == 0:\n",
        "      reversed_pert = unc_defense_epistemic(pert, model_cnn, eps_little, num_iter_reverse, alpha_reverse)\n",
        "    elif input_a == 1:\n",
        "      reversed_pert = unc_defense_scibilic(pert, model_cnn, eps_little, num_iter_reverse, alpha_reverse)\n",
        "    elif input_a == 2:\n",
        "      reversed_pert = unc_defense_scibilic_pred(pert, model_cnn, eps_little, num_iter_reverse, alpha_reverse,pred_pert)\n",
        "\n",
        "    model_cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn(reversed_pert)\n",
        "        o = softmax(o)\n",
        "    pred_reverse = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    pred_reverse = pred_reverse.view_as(label)\n",
        "\n",
        "    inds_correct_after_reverse = np.where(pred_reverse.cpu() == label.cpu())[0]\n",
        "    inds_wrong_after_reverse = np.where(pred_reverse.cpu() != label.cpu())[0]\n",
        "\n",
        "    inds_correct_after_reverse = inds_correct_after_reverse.tolist()\n",
        "    inds_wrong_after_reverse = inds_wrong_after_reverse.tolist()\n",
        "\n",
        "    count_successful_reverse += len(inds_correct_after_reverse)\n",
        "    count_unsuccessful_reverse += len(inds_wrong_after_reverse)\n",
        "\n",
        "    # if i == 0:\n",
        "    #     break"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V62DntrMlHw3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95660d91-cecc-4678-d6de-c55fdeee2f59"
      },
      "source": [
        "print(\"Number of successful reverse operation is : \", count_successful_reverse)\n",
        "print(\"Number of unsuccessful reverse operation is : \", count_unsuccessful_reverse)\n",
        "\n",
        "reformatted_GMT_timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "print(reformatted_GMT_timestamp)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of successful reverse operation is :  7297\n",
            "Number of unsuccessful reverse operation is :  641\n",
            "2021-07-02 16:14:08\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}